import Link from '@docusaurus/Link';

The health of Kafka partitions often reflects the health of the brokers that host them. Thus, when alerts occur for conditions such as under-replicated partitions or more frequent leadership transfers, check for unresponsive or unavailable brokers.

With Redpanda's internal implementation of the Raft consensus protocol, the health of partitions is also reflected in any errors in the internal RPCs exchanged between Raft peers.

#### Leadership changes

Stable clusters have a consistent balance of leaders across all brokers, with few to no leadership transfers between brokers.

To observe changes in leadership, monitor the <Link to={props.frontmatter && props.frontmatter.linkRoot + 'reference/public-metrics-reference#redpanda_raft_leadership_changes'}>`redpanda_raft_leadership_changes`</Link> counter. For example, use a query to get the total rate of increase of leadership changes for a cluster:

```
sum(rate(redpanda_raft_leadership_changes{redpanda_cloud_data_cluster_name=<cluster-name>}[5m]))
```
 
#### Under-replicated partitions

A healthy cluster has partition data fully replicated across its brokers. 

An under-replicated partition is at higher risk of data loss. It also adds latency because messages must be replicated before being committed. To know when a partition isn't fully replicated, create an alert for the <Link to={props.frontmatter && props.frontmatter.linkRoot + 'reference/public-metrics-reference#redpanda_kafka_under_replicated_replicas'}>`redpanda_kafka_under_replicated_replicas`</Link> gauge when it is greater than zero:

```
redpanda_kafka_under_replicated_replicas > 0
```

Under-replication can be caused by unresponsive brokers. When an alert on `redpanda_kafka_under_replicated_replicas` is triggered, identify the problem brokers and examine their logs. 

#### Leaderless partitions

A healthy cluster has a leader for every partition. 

A partition without a leader cannot exchange messages with producers or consumers. To identify when a partition doesn't have a leader, create an alert for the <Link to={props.frontmatter && props.frontmatter.linkRoot + 'reference/public-metrics-reference#redpanda_cluster_unavailable_partitions'}>`redpanda_cluster_unavailable_partitions`</Link> gauge when it is greater than zero: 

```
redpanda_cluster_unavailable_partitions > 0
```

Leaderless partitions can be caused by unresponsive brokers. When an alert on `redpanda_cluster_unavailable_partitions` is triggered, identify the problem brokers and examine their logs. 

#### Raft RPCs

Redpanda's Raft implementation exchanges periodic status RPCs between a broker and its peers. The <Link to={props.frontmatter && props.frontmatter.linkRoot + 'reference/public-metrics-reference#redpanda_node_status_rpcs_timed_out'}>`redpanda_node_status_rpcs_timed_out`</Link> gauge increases when a status RPC times out for a peer, which indicates that a peer may be unresponsive and may lead to problems with partition replication that Raft manages. Monitor for non-zero values of this gauge, and correlate it with any logged errors or changes in partition replication.
